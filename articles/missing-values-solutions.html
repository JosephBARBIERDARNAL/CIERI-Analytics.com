<!DOCTYPE html>
<html lang="en">
<head>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script type="text/javascript" id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-W4TQWGW3QY"></script>
    <script src="/script/google-analytics.js"></script>
    <meta charset="UTF-8">
    <meta http-equiv="Cache-control" content="no-cache">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="CIERI Analytics is a blog about identity, behavior and data science">
    <meta name="keywords" content="missing, values, NA, NaN, imputation, analytics, data science, identity, data, science, machine learning, artificial intelligence, AI, ML, statistics, R, python, data analysis, research, behavior, psychology, social science">
    <meta name="author" content="Thomas Salanova and Joseph Barbier">
    <title>CIERI Analytics</title>
    <link rel="stylesheet" href="/css/main.css">
</head>

<body>    
    <div id="header-container"></div>
    <br>
    <br>

    <div class="container">
        <h1>Missing values: how to go beyond the mean and the mode?</h2><hr>
        <p>
            Missing values (NA or NaN) is one of the most common problems in data science. NA values can be
            problematic because they can lead to biased results. For example, if you want to know the average
            revenue of a population, and you have missing values, you might have problems such as:
            <ul>
                <li>Maybe rich people are more likely to not answer the question</li>
                <li>Maybe poor people are more likely to not answer the question</li>
                <li>Maybe people who are not rich nor poor are more likely to not answer the question</li>
                <li>Maybe NA values are randomly distributed</li>
            </ul>
            In this post, we will go over the following points:
            <ul>
                <li>Why not keeping the NA?</li>
                <li>What are the different types of missing values?</li>
                <li>Easy and better solutions than the mean and the mode</li>
                <li>More complex solutions</li>
            </ul>
        </p>

        <br>
        <br>
        <br>
        <br>

        <h2>Why not keeping the NA?</h2><hr>
        <p>
            A naive solution to the problem of missing values is to just keep the NA values.
            Even tough NA generally cause problems when doing statistical analysis, there are tools
            that allow you to keep the NA values. For example, you can use a <a
            href='https://scikit-learn.org/stable/modules/ensemble.html#histogram-based-gradient-boosting'
            target="_blank"> histogram-based gradient boosting</a> model that can handle NA values. These models can work
            either with numerical or categorical variables. However, this solution is not always the best
            and does not allows you to explore as much as you would like your data.
        </p>

        <br>
        <br>
        <br>

        <h2>Different types of missing values</h2><hr>
        <p>
            There are different types of missing values:
            <ul>
                <li>MCAR: Missing Completely At Random. This concerns NA whose absence is determined purely
                    at random and does not depend on the individuals. This is a rather rare situation.</li>
                <li>MAR: Missing At Random. The probability of being missing is the same only within groups
                    defined by the observed data. The missingness is related to the observed data but not
                    the unobserved data.</li>
                <li>MNAR: Missing Not At Random. The probability of being missing varies for reasons that are 
                    unknown to the researcher and related to the missing data itself.</li>
                <li>Structurally missing. Missingness that occurs due to the structure of the data. For
                    example, in a survey, a question about pregnancy might only be presented to female
                    respondents, so male respondents would have structurally missing values for this item.</li>
            </ul>
        </p>
        <p>
            Why does it matter? Because the way you deal with NA depends on the type of missing
            values. For example, if you have MCAR and a high enough sample size, you can just drop the rows
            with NA. If you have MNAR, your estimations will be biased if you do not take into
            account the NA.
        </p>

        <br>
        <br>
        <br>

        <h2>Easy and better solutions than the mean and the mode</h2><hr>
        <p>
            It's a very common practice to replace NA values by the mean or the mode. However, this is not
            a very good practice. Indeed, this practice can lead to biased results. For example, if you have
            missing values in the Age variable, and you replace the NA values by the mean, you will have a
            lower Age variance. The good news is that maybe you don't even need to replace the NA values with
            an estimation!
        </p>
        <p>
            At each of the 3 following steps, you should check if there are still NA, because it's not 
            necessarily the case after. 
        </p>
        <br><h3>1 - Very first thing to do</h3>
        <p>
            The very first you should do before anything is to drop observations/variables that have
            100% NA values. By doing this, you don't take any risk (these observations/variables couldn't
            be used anyway) and you reduce the number of NA.
        </p>
        <br><h3>2 - Search for structurally missing values</h3>
        <p>
            Then, you should check if there are structurally missing values. For example, if you have a
            variable about the number of cigarettes consumed per day with NA values, you should check if
            these NA values are for non-smokers. If it's the case, you can replace the NA values by 0.
            This can bring lots of work if you have lots of variables, but it's the best way to deal with
            structurally missing values. Also, it means that you should have a good understanding of the
            data you are working with.
        </p>
        <br><h3>3 - Replace NA by a new category</h3>
        <p>
            If you have categorical variables, you can replace NA values by a new category. For example,
            if you have a variable about the marital status with NA values, you can replace the NA values
            by "unknown", also known as explicit NA. By doing this, you don't take any risk and you don't lose information. The one
            problem that comes with it is that you increase the number of categories and that maybe all
            married people will be categorized as "married" and "unknown", which is not ideal.
        </p>
        <br>
        <p>
            With these three steps, you have a good start of reducing the number of NA values without
            using any estimation and made your data more understandable. However, you might still have
            NA values, especially in numerical variables.
        </p>
    
        <br>
        <br>
        <br>

        <h2>More complex solutions</h2><hr>
        <p>
            If you still have NA values, you can use more complex solutions. These solutions are more
            complex because they use estimations, modelling, etc. However, they are still easy to
            implement and can bring a lot of value to your analysis.
        </p>
        <p>
            We'll go over 3 solutions with references on how to implement them in Python and R:
            <ul>
                <li>Imputation by regression</li>
                <li>Imputation by KNN</li>
                <li>Imputation by MICE</li>
            </ul>
        </p>
        <p>
            This section is a work in progress.
        </p>

        <br>
        <br>
        <br>

        <h2>Going further</h2><hr>
        <p>
            In this post, we saw that the "all other things being equal" expression is used to say that you are
            looking at the effect of one variable on another, while keeping all other variables constant. We also
            saw that this expression has an impact on the interpretation of the coefficients. Finally, we saw that
            the Frisch-Waugh-Lovell theorem is a theorem that allows you to get the same results as if you had
            run a regression with all the variables, while only running a regression with one variable.
        </p>
        <p>
            If you want to go further, check:
            <ul>
                <li><a href="/articles/ai-vs-machine-learning.html">Difference between artificial intelligence and machine learning</a></li>
                <li><a href="/articles/all-other-things-being-equal.html">All other things being equal: what does this really mean?</a></li>
            </ul>
        </p>
        <p>
            This post is the work of <a href='/about.html'>Joseph Barbier and Thomas Salanova</a>. If you have
            any questions, feel free to <a href='mailto:joseph.barbierdarnal@gmail.com' target="_blank">contact us</a>!
        </p>

    </div> <!-- end container -->
<div id="footer-container"></div>

<script src="/script/button-switch-language.js"></script>
<script src="/script/load-header-footer.js"></script>

</body>
</html>
